{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6cQf7WdSn+bKQDH3xWedx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b863c26f4094bfcaa096061b63e39c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_671f4ae05fc3467492bdfd9046e77e08",
              "IPY_MODEL_cf070ee28ccb4b108945a56ec971847b",
              "IPY_MODEL_9841edce407f4d799568d01c18b65506"
            ],
            "layout": "IPY_MODEL_963aacd2ec6248049e32931ad1491152"
          }
        },
        "671f4ae05fc3467492bdfd9046e77e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb27c8de1634f078bc89a88a0cc1e1f",
            "placeholder": "​",
            "style": "IPY_MODEL_73ab61e54580407e8a30bb8c26eddb9e",
            "value": "genrt: 100%"
          }
        },
        "cf070ee28ccb4b108945a56ec971847b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78296e7cca10413da4817699ca92746d",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b85cacc72784d5d9dee79462184b3b2",
            "value": 200
          }
        },
        "9841edce407f4d799568d01c18b65506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c43ae4ad2954e07985ca9405c446ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_ac831c77eb084ceaa6a507001df60c54",
            "value": " 200/200 [00:23&lt;00:00,  6.85it/s]"
          }
        },
        "963aacd2ec6248049e32931ad1491152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb27c8de1634f078bc89a88a0cc1e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ab61e54580407e8a30bb8c26eddb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78296e7cca10413da4817699ca92746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b85cacc72784d5d9dee79462184b3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c43ae4ad2954e07985ca9405c446ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac831c77eb084ceaa6a507001df60c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itachi8374/Piano-Music-Generation/blob/main/piano_music_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMJ7IgvNINhs"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install pretty_midi\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import glob\n",
        "import random\n",
        "import pretty_midi\n",
        "import IPython\n",
        "import numpy as np\n",
        "from tqdm import tnrange, tqdm_notebook, tqdm\n",
        "from random import shuffle, seed\n",
        "import numpy as np\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "import numpy as np\n",
        "from numpy.random import choice\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
        "    '''Convert a Piano Roll array into a PrettyMidi object\n",
        "     with a single instrument.\n",
        "    Parameters\n",
        "    ----------\n",
        "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
        "        Piano roll of one instrument\n",
        "    fs : int\n",
        "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
        "        by ``1./fs`` seconds.\n",
        "    program : int\n",
        "        The program number of the instrument.\n",
        "    Returns\n",
        "    -------\n",
        "    midi_object : pretty_midi.PrettyMIDI\n",
        "        A pretty_midi.PrettyMIDI class instance describing\n",
        "        the piano roll.\n",
        "    '''\n",
        "    notes, frames = piano_roll.shape\n",
        "    pm = pretty_midi.PrettyMIDI()\n",
        "    instrument = pretty_midi.Instrument(program=program)\n",
        "\n",
        "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
        "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
        "\n",
        "    # use changes in velocities to find note on / note off events\n",
        "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
        "\n",
        "    # keep track on velocities and note on times\n",
        "    prev_velocities = np.zeros(notes, dtype=int)\n",
        "    note_on_time = np.zeros(notes)\n",
        "\n",
        "    for time, note in zip(*velocity_changes):\n",
        "        # use time + 1 because of padding above\n",
        "        velocity = piano_roll[note, time + 1]\n",
        "        time = time / fs\n",
        "        if velocity > 0:\n",
        "            if prev_velocities[note] == 0:\n",
        "                note_on_time[note] = time\n",
        "                prev_velocities[note] = velocity\n",
        "        else:\n",
        "            pm_note = pretty_midi.Note(\n",
        "                velocity=prev_velocities[note],\n",
        "                pitch=note,\n",
        "                start=note_on_time[note],\n",
        "                end=time)\n",
        "            instrument.notes.append(pm_note)\n",
        "            prev_velocities[note] = 0\n",
        "    pm.instruments.append(instrument)\n",
        "    return pm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NoteTokenizer:\n",
        "    \n",
        "    def __init__(self):\n",
        "      self.notes_to_index = {}\n",
        "      self.index_to_notes = {}\n",
        "      self.num_of_word = 0\n",
        "      self.unique_word = 0\n",
        "      self.notes_freq = {}\n",
        "        \n",
        "    def transform(self,list_array):\n",
        "      \"\"\" Transform a list of note in string into index.\n",
        "      \n",
        "      Parameters\n",
        "      ==========\n",
        "      list_array : list\n",
        "        list of note in string format\n",
        "      \n",
        "      Returns\n",
        "      =======\n",
        "      The transformed list in numpy array.\n",
        "      \n",
        "      \"\"\"\n",
        "      transformed_list = []\n",
        "      for instance in list_array:\n",
        "          transformed_list.append([self.notes_to_index[note] for note in instance])\n",
        "      return np.array(transformed_list, dtype=np.int32)\n",
        " \n",
        "    def partial_fit(self, notes):\n",
        "        \"\"\" Partial fit on the dictionary of the tokenizer\n",
        "        \n",
        "        Parameters\n",
        "        ==========\n",
        "        notes : list of notes\n",
        "        \n",
        "        \"\"\"\n",
        "        for note in notes:\n",
        "            note_str = ','.join(str(a) for a in note)\n",
        "            if note_str in self.notes_freq:\n",
        "                self.notes_freq[note_str] += 1\n",
        "                self.num_of_word += 1\n",
        "            else:\n",
        "                self.notes_freq[note_str] = 1\n",
        "                self.unique_word += 1\n",
        "                self.num_of_word += 1\n",
        "                self.notes_to_index[note_str], self.index_to_notes[self.unique_word] = self.unique_word, note_str\n",
        "            \n",
        "    def add_new_note(self, note):\n",
        "        \"\"\" Add a new note into the dictionary\n",
        "\n",
        "        Parameters\n",
        "        ==========\n",
        "        note : str\n",
        "          a new note who is not in dictionary.  \n",
        "\n",
        "        \"\"\"\n",
        "        assert note not in self.notes_to_index\n",
        "        self.unique_word += 1\n",
        "        self.notes_to_index[note], self.index_to_notes[self.unique_word] = self.unique_word, note"
      ],
      "metadata": {
        "id": "aso39nLiLggf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqSelfAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    ATTENTION_TYPE_ADD = 'additive'\n",
        "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
        "\n",
        "    def __init__(self,\n",
        "                 units=32,\n",
        "                 attention_width=None,\n",
        "                 attention_type=ATTENTION_TYPE_ADD,\n",
        "                 return_attention=False,\n",
        "                 history_only=False,\n",
        "                 kernel_initializer='glorot_normal',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 use_additive_bias=True,\n",
        "                 use_attention_bias=True,\n",
        "                 attention_activation=None,\n",
        "                 attention_regularizer_weight=0.0,\n",
        "                 **kwargs):\n",
        "        \"\"\"Layer initialization.\n",
        "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
        "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
        "        :param attention_width: The width of local attention.\n",
        "        :param attention_type: 'additive' or 'multiplicative'.\n",
        "        :param return_attention: Whether to return the attention weights for visualization.\n",
        "        :param history_only: Only use historical pieces of data.\n",
        "        :param kernel_initializer: The initializer for weight matrices.\n",
        "        :param bias_initializer: The initializer for biases.\n",
        "        :param kernel_regularizer: The regularization for weight matrices.\n",
        "        :param bias_regularizer: The regularization for biases.\n",
        "        :param kernel_constraint: The constraint for weight matrices.\n",
        "        :param bias_constraint: The constraint for biases.\n",
        "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
        "                                  in additive mode.\n",
        "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
        "        :param attention_activation: The activation used for calculating the weights of attention.\n",
        "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
        "        :param kwargs: Parameters for parent class.\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        self.units = units\n",
        "        self.attention_width = attention_width\n",
        "        self.attention_type = attention_type\n",
        "        self.return_attention = return_attention\n",
        "        self.history_only = history_only\n",
        "        if history_only and attention_width is None:\n",
        "            self.attention_width = int(1e9)\n",
        "\n",
        "        self.use_additive_bias = use_additive_bias\n",
        "        self.use_attention_bias = use_attention_bias\n",
        "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
        "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
        "        self.attention_activation = tf.keras.activations.get(attention_activation)\n",
        "        self.attention_regularizer_weight = attention_regularizer_weight\n",
        "        self._backend = tf.keras.backend.backend()\n",
        "\n",
        "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
        "            self.Wx, self.Wt, self.bh = None, None, None\n",
        "            self.Wa, self.ba = None, None\n",
        "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
        "            self.Wa, self.ba = None, None\n",
        "        else:\n",
        "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
        "\n",
        "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'units': self.units,\n",
        "            'attention_width': self.attention_width,\n",
        "            'attention_type': self.attention_type,\n",
        "            'return_attention': self.return_attention,\n",
        "            'history_only': self.history_only,\n",
        "            'use_additive_bias': self.use_additive_bias,\n",
        "            'use_attention_bias': self.use_attention_bias,\n",
        "            'kernel_initializer': tf.keras.regularizers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': tf.keras.regularizers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': tf.keras.regularizers.serialize(self.bias_regularizer),\n",
        "            'kernel_constraint': tf.keras.constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': tf.keras.constraints.serialize(self.bias_constraint),\n",
        "            'attention_activation': tf.keras.activations.serialize(self.attention_activation),\n",
        "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
        "        }\n",
        "        base_config = super(SeqSelfAttention, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
        "            self._build_additive_attention(input_shape)\n",
        "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
        "            self._build_multiplicative_attention(input_shape)\n",
        "        super(SeqSelfAttention, self).build(input_shape)\n",
        "\n",
        "    def _build_additive_attention(self, input_shape):\n",
        "        feature_dim = input_shape[2]\n",
        "\n",
        "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='{}_Add_Wt'.format(self.name),\n",
        "                                  initializer=self.kernel_initializer,\n",
        "                                  regularizer=self.kernel_regularizer,\n",
        "                                  constraint=self.kernel_constraint)\n",
        "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
        "                                  name='{}_Add_Wx'.format(self.name),\n",
        "                                  initializer=self.kernel_initializer,\n",
        "                                  regularizer=self.kernel_regularizer,\n",
        "                                  constraint=self.kernel_constraint)\n",
        "        if self.use_additive_bias:\n",
        "            self.bh = self.add_weight(shape=(self.units,),\n",
        "                                      name='{}_Add_bh'.format(self.name),\n",
        "                                      initializer=self.bias_initializer,\n",
        "                                      regularizer=self.bias_regularizer,\n",
        "                                      constraint=self.bias_constraint)\n",
        "\n",
        "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
        "                                  name='{}_Add_Wa'.format(self.name),\n",
        "                                  initializer=self.kernel_initializer,\n",
        "                                  regularizer=self.kernel_regularizer,\n",
        "                                  constraint=self.kernel_constraint)\n",
        "        if self.use_attention_bias:\n",
        "            self.ba = self.add_weight(shape=(1,),\n",
        "                                      name='{}_Add_ba'.format(self.name),\n",
        "                                      initializer=self.bias_initializer,\n",
        "                                      regularizer=self.bias_regularizer,\n",
        "                                      constraint=self.bias_constraint)\n",
        "\n",
        "    def _build_multiplicative_attention(self, input_shape):\n",
        "        feature_dim = input_shape[2]\n",
        "\n",
        "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
        "                                  name='{}_Mul_Wa'.format(self.name),\n",
        "                                  initializer=self.kernel_initializer,\n",
        "                                  regularizer=self.kernel_regularizer,\n",
        "                                  constraint=self.kernel_constraint)\n",
        "        if self.use_attention_bias:\n",
        "            self.ba = self.add_weight(shape=(1,),\n",
        "                                      name='{}_Mul_ba'.format(self.name),\n",
        "                                      initializer=self.bias_initializer,\n",
        "                                      regularizer=self.bias_regularizer,\n",
        "                                      constraint=self.bias_constraint)\n",
        "\n",
        "    def call(self, inputs, mask=None, **kwargs):\n",
        "        if isinstance(inputs, list):\n",
        "            inputs, positions = inputs\n",
        "            positions = K.cast(positions, 'int32')\n",
        "            mask = mask[1]\n",
        "        else:\n",
        "            positions = None\n",
        "\n",
        "        input_len = K.shape(inputs)[1]\n",
        "\n",
        "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
        "            e = self._call_additive_emission(inputs)\n",
        "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
        "            e = self._call_multiplicative_emission(inputs)\n",
        "\n",
        "        if self.attention_activation is not None:\n",
        "            e = self.attention_activation(e)\n",
        "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "        if self.attention_width is not None:\n",
        "            ones = tf.ones((input_len, input_len))\n",
        "            if self.history_only:\n",
        "                local = tf.linalg.band_part(\n",
        "                    ones,\n",
        "                    K.minimum(input_len, self.attention_width - 1),\n",
        "                    0,\n",
        "                )\n",
        "            else:\n",
        "                local = tf.linalg.band_part(\n",
        "                    ones,\n",
        "                    K.minimum(input_len, self.attention_width // 2),\n",
        "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
        "                )\n",
        "            e = e * K.expand_dims(local, 0)\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            mask = K.expand_dims(mask)\n",
        "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
        "\n",
        "        # a_{t} = \\text{softmax}(e_t)\n",
        "        s = K.sum(e, axis=-1)\n",
        "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
        "        a = e / (s + K.epsilon())\n",
        "\n",
        "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
        "        v = K.batch_dot(a, inputs)\n",
        "        if self.attention_regularizer_weight > 0.0:\n",
        "            self.add_loss(self._attention_regularizer(a))\n",
        "\n",
        "        if positions is not None:\n",
        "            pos_num = K.shape(positions)[1]\n",
        "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
        "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
        "            v = tf.gather_nd(v, pos_indices)\n",
        "            a = tf.gather_nd(a, pos_indices)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return [v, a]\n",
        "        return v\n",
        "\n",
        "    def _call_additive_emission(self, inputs):\n",
        "        input_shape = K.shape(inputs)\n",
        "        batch_size, input_len = input_shape[0], input_shape[1]\n",
        "\n",
        "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
        "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
        "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
        "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
        "        if self.use_additive_bias:\n",
        "            h = K.tanh(q + k + self.bh)\n",
        "        else:\n",
        "            h = K.tanh(q + k)\n",
        "\n",
        "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
        "        if self.use_attention_bias:\n",
        "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
        "        else:\n",
        "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
        "        return e\n",
        "\n",
        "    def _call_multiplicative_emission(self, inputs):\n",
        "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
        "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
        "        if self.use_attention_bias:\n",
        "            e = e + self.ba\n",
        "        return e\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape, pos_shape = input_shape\n",
        "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
        "        else:\n",
        "            output_shape = input_shape\n",
        "        if self.return_attention:\n",
        "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
        "            return [output_shape, attention_shape]\n",
        "        return output_shape\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if isinstance(inputs, list):\n",
        "            mask = mask[1]\n",
        "        if self.return_attention:\n",
        "            return [mask, None]\n",
        "        return mask\n",
        "\n",
        "    def _attention_regularizer(self, attention):\n",
        "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
        "        input_len = K.shape(attention)[-1]\n",
        "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
        "            attention,\n",
        "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def get_custom_objects():\n",
        "      return {'SeqSelfAttention': SeqSelfAttention}"
      ],
      "metadata": {
        "id": "9b8h013HIQ4Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('model_ep4.h5', custom_objects=SeqSelfAttention.get_custom_objects())\n",
        "note_tokenizer  = pickle.load( open( \"tokenizer.p\", \"rb\" ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjMpVUioIuUh",
        "outputId": "ec4491a2-beb4-4014-997e-0377f20e7ea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_from_random(unique_notes, seq_len=50):\n",
        "  generate = np.random.randint(0,unique_notes,seq_len).tolist()\n",
        "  return generate\n",
        "    \n",
        "def generate_from_one_note(note_tokenizer, new_notes='35'):\n",
        "  generate = [note_tokenizer.notes_to_index['e'] for i in range(49)]\n",
        "  generate += [note_tokenizer.notes_to_index[new_notes]]\n",
        "  return generate"
      ],
      "metadata": {
        "id": "QM_ec133JJ5c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(generate, model, unique_notes, max_generated=1000, seq_len=50):\n",
        "  for i in tqdm_notebook(range(max_generated), desc='genrt'):\n",
        "    test_input = np.array([generate])[:,i:i+seq_len]\n",
        "    predicted_note = model.predict(test_input)\n",
        "    random_note_pred = choice(unique_notes+1, 1, replace=False, p=predicted_note[0])\n",
        "    generate.append(random_note_pred[0])\n",
        "  return generate"
      ],
      "metadata": {
        "id": "j9mRPNCdMBuu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_midi_file_from_generated(generate, midi_file_name = \"result.mid\", start_index=49, fs=8, max_generated=1000):\n",
        "  note_string = [note_tokenizer.index_to_notes[ind_note] for ind_note in generate]\n",
        "  array_piano_roll = np.zeros((128,max_generated+1), dtype=np.int16)\n",
        "  for index, note in enumerate(note_string[start_index:]):\n",
        "    if note == 'e':\n",
        "      pass\n",
        "    else:\n",
        "      splitted_note = note.split(',')\n",
        "      for j in splitted_note:\n",
        "        array_piano_roll[int(j),index] = 1\n",
        "  generate_to_midi = piano_roll_to_pretty_midi(array_piano_roll, fs=fs)\n",
        "  print(\"Tempo {}\".format(generate_to_midi.estimate_tempo()))\n",
        "  for note in generate_to_midi.instruments[0].notes:\n",
        "    note.velocity = 100\n",
        "  generate_to_midi.write(midi_file_name)"
      ],
      "metadata": {
        "id": "VeVWVZRNMG6D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_generate = 200\n",
        "unique_notes = note_tokenizer.unique_word\n",
        "seq_len=50\n",
        "generate = generate_from_random(unique_notes, seq_len)\n",
        "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
        "write_midi_file_from_generated(generate, \"random.mid\", start_index=seq_len-1, fs=7, max_generated = max_generate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b863c26f4094bfcaa096061b63e39c3",
            "671f4ae05fc3467492bdfd9046e77e08",
            "cf070ee28ccb4b108945a56ec971847b",
            "9841edce407f4d799568d01c18b65506",
            "963aacd2ec6248049e32931ad1491152",
            "4eb27c8de1634f078bc89a88a0cc1e1f",
            "73ab61e54580407e8a30bb8c26eddb9e",
            "78296e7cca10413da4817699ca92746d",
            "4b85cacc72784d5d9dee79462184b3b2",
            "7c43ae4ad2954e07985ca9405c446ea0",
            "ac831c77eb084ceaa6a507001df60c54"
          ]
        },
        "id": "gne2OTrlMKYh",
        "outputId": "1074f7d3-a100-4ed5-b1fa-9757267bdc8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-64f7dc68ef53>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm_notebook(range(max_generated), desc='genrt'):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "genrt:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b863c26f4094bfcaa096061b63e39c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Tempo 209.99999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BD2NYZO5MNiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}